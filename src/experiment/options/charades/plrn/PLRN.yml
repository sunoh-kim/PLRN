model:
    model_type: "PLRN"
    resume: False 
    checkpoint_path: ""
    use_gpu: True
    ### Video Encoder
    use_video_encoder: False
    video_enc_vemb_idim: 1024
    video_enc_vemb_odim: 512 # (=vdim)
    video_enc_use_position: True
    video_enc_pemb_idim: 128
    video_enc_pemb_odim: 512
    ### Query Encoder
    query_enc_emb_idim: -1 # == vocabulary size
    query_enc_emb_odim: 300 # == dim of Glove
    query_enc_rnn_type: "LSTM"
    query_enc_rnn_bidirectional: True
    query_enc_rnn_nlayer: 2
    query_enc_rnn_idim: -1 # == query_emb_odim
    query_enc_rnn_hdim: 256 # (=qdim)
    query_enc_rnn_dropout: 0.5
    query_enc_use_position: True
    query_enc_pemb_idim: -1 # (=max_length)
    query_enc_pemb_odim: 300
    glove_path: ""
    ### Query Attention Network (QAN)
    qan_qdim: -1 # == qdim
    qan_att_cand_dim: -1 # == qdim
    qan_att_key_dim: -1 # == qdim
    qan_att_hdim: 256
    qan_att_drop_prob: 0.0
    ### Local-Global Video-Text interactions (LGI)
    lgi_fusion_method: "mul" # mul concat
    lgi_hp_idim_1: -1 # == qdim
    lgi_hp_idim_2: -1 # == qdim
    lgi_hp_hdim: -1 # == vdim
    lgi_local_type: "res_block"
    lgi_local_res_block_1d_idim: -1 # == vdim
    lgi_local_res_block_1d_odim: -1 # == vdim
    lgi_local_res_block_1d_hdim: 256
    lgi_local_res_block_1d_ksize: 15 # 15
    lgi_local_num_res_blocks: 1 # 1
    lgi_local_do_downsample: False
    lgi_local_nl_idim: 512 # == vdim
    lgi_local_nl_odim: 512
    lgi_local_nl_nheads: 4 # 4
    lgi_local_num_nl_block: 2 # 2
    lgi_local_nl_use_local_mask: False
    lgi_global_type: "nl"
    lgi_global_satt_att_n: 1
    lgi_global_satt_att_cand_dim: -1 # == vdim
    lgi_global_satt_att_hdim: 256
    lgi_global_satt_att_use_embedding: True
    lgi_global_satt_att_edim: 512
    lgi_global_num_nl_block: 2
    lgi_global_nl_idim: 1 # == vdim
    lgi_global_nl_odim: 512
    lgi_global_nl_nheads: 4
    lgi_global_nl_use_bias: True
    lgi_global_nl_drop_prob: 0.0
    lgi_global_nl_use_local_mask: False
    ### Temporal Attention based Regression
    grounding_att_key_dim: -1
    grounding_att_cand_dim: -1
    grounding_att_hdim: 256
    grounding_att_drop_prob: 0.0
    grounding_idim: -1
    grounding_hdim: 512
    ### Criterion
    use_temporal_attention_guidance_loss: True
    tag_weight: 1.0
    dqa_weight: 1.0
    dqa_lambda: 0.3
    use_center_width_regression_loss: True
    contextmodeling_att_key_dim: -1
    contextmodeling_att_cand_dim: -1
    contextmodeling_att_hdim: 256
    contextmodeling_att_drop_prob: 0.0
train_loader:
    dataset: "charades"
    split: "train"
    in_memory: True
    #in_memory: False
    batch_size: 100
    data_dir: "/home/pil-kso/PycharmProjects/Dataset/charades"  # "/media/E/data/charades"
    video_feature_path: "/home/pil-kso/PycharmProjects/Dataset/charades/features/i3d_finetuned/{}.npy" # "/media/E/data/charades/features/i3d_finetuned/{}.npy"
    max_length: 10
    word_frequency_threshold: 1
    num_segment: 128
test_loader:
    dataset: "charades"
    split: "test"
    in_memory: True
    #in_memory: False
    batch_size: 100
    data_dir: "/home/pil-kso/PycharmProjects/Dataset/charades"  # "/media/E/data/charades"
    video_feature_path: "/home/pil-kso/PycharmProjects/Dataset/charades/features/i3d_finetuned/{}.npy"  # "/media/E/data/charades/features/i3d_finetuned/{}.npy"
    max_length: 10
    word_frequency_threshold: 1
    num_segment: 128
optimize:
    num_step: 500 # epoch
    optimizer_type: "Adam"
    init_lr: 0.0004
    scheduler_type: ""
    decay_factor: 0.5
    decay_step: -1
evaluation:
    evaluate_after: -1
    every_eval: 1 
    print_every: 100
misc:
    print_every: 100
    vis_every: 100
logging:
    print_level: "DEBUG"
    write_level: "INFO"
